# -*- coding: utf-8 -*-
"""Going modular.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x-sTXjRrC_fwYz_uajG7OMkl0lzXYRJ6
"""

import torch
import torchvision
print(torch.__version__)
print(torchvision.__version__)



"""# 1. Turn the data into get data.py file"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile get_data.py
# import os
# import zipfile
# 
# from pathlib import Path
# 
# import requests
# 
# # Setup path to data folder
# data_path = Path("data/")
# image_path = data_path / "pizza_steak_sushi"
# 
# # If the image folder doesn't exist, download it and prepare it...
# if image_path.is_dir():
#     print(f"{image_path} directory exists.")
# else:
#     print(f"Did not find {image_path} directory, creating one...")
#     image_path.mkdir(parents=True, exist_ok=True)
# 
# # Download pizza, steak, sushi data
# with open(data_path / "pizza_steak_sushi.zip", "wb") as f:
#     request = requests.get("https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip")
#     print("Downloading pizza, steak, sushi data...")
#     f.write(request.content)
# 
# # Unzip pizza, steak, sushi data
# with zipfile.ZipFile(data_path / "pizza_steak_sushi.zip", "r") as zip_ref:
#     print("Unzipping pizza, steak, sushi data...")
#     zip_ref.extractall(image_path)
# 
# # Remove zip file
# os.remove(data_path / "pizza_steak_sushi.zip")

"""# 2. Use Python's argparse module to be able to send the train.py custom hyperparameter values for training procedures."""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile data_setup.py
# """
# Contains functionality for creating PyTorch DataLoaders for
# image classification data.
# """
# import os
# 
# from torchvision import datasets, transforms
# from torch.utils.data import DataLoader
# 
# NUM_WORKERS = os.cpu_count()
# 
# def create_dataloaders(
#     train_dir: str,
#     test_dir: str,
#     transform: transforms.Compose,
#     batch_size: int,
#     num_workers: int=NUM_WORKERS
# ):
# 
#   # Use ImageFolder to create dataset(s)
#   train_data = datasets.ImageFolder(train_dir, transform=transform)
#   test_data = datasets.ImageFolder(test_dir, transform=transform)
# 
#   # Get class names
#   class_names = train_data.classes
# 
#   # Turn images into data loaders
#   train_dataloader = DataLoader(
#       train_data,
#       batch_size=batch_size,
#       shuffle=True,
#       num_workers=num_workers,
#       pin_memory=True,
#   )
#   test_dataloader = DataLoader(
#       test_data,
#       batch_size=batch_size,
#       shuffle=False,
#       num_workers=num_workers,
#       pin_memory=True,
#   )
# 
#   return train_dataloader, test_dataloader, class_names

# Commented out IPython magic to ensure Python compatibility.
# 
# %%writefile engine.py
# """
# Contains functions for training and testing a PyTorch model.
# """
# import torch
# 
# from tqdm.auto import tqdm
# from typing import Dict, List, Tuple
# 
# def train_step(model: torch.nn.Module,
#                dataloader: torch.utils.data.DataLoader,
#                loss_fn: torch.nn.Module,
#                optimizer: torch.optim.Optimizer,
#                device: torch.device) -> Tuple[float, float]:
#     """Trains a PyTorch model for a single epoch.
#     Turns a target PyTorch model to training mode and then
#     runs through all of the required training steps (forward
#     pass, loss calculation, optimizer step).
#     Args:
#     model: A PyTorch model to be trained.
#     dataloader: A DataLoader instance for the model to be trained on.
#     loss_fn: A PyTorch loss function to minimize.
#     optimizer: A PyTorch optimizer to help minimize the loss function.
#     device: A target device to compute on (e.g. "cuda" or "cpu").
#     Returns:
#     A tuple of training loss and training accuracy metrics.
#     In the form (train_loss, train_accuracy). For example:
#     (0.1112, 0.8743)
#     """
#     # Put model in train mode
#     model.train()
# 
#     # Setup train loss and train accuracy values
#     train_loss, train_acc = 0, 0
# 
#     # Loop through data loader data batches
#     for batch, (X, y) in enumerate(dataloader):
#         # Send data to target device
#         X, y = X.to(device), y.to(device)
# 
#         # 1. Forward pass
#         y_pred = model(X)
# 
#         # 2. Calculate  and accumulate loss
#         loss = loss_fn(y_pred, y)
#         train_loss += loss.item()
# 
#         # 3. Optimizer zero grad
#         optimizer.zero_grad()
# 
#         # 4. Loss backward
#         loss.backward()
# 
#         # 5. Optimizer step
#         optimizer.step()
# 
#         # Calculate and accumulate accuracy metric across all batches
#         y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)
#         train_acc += (y_pred_class == y).sum().item()/len(y_pred)
# 
#     # Adjust metrics to get average loss and accuracy per batch
#     train_loss = train_loss / len(dataloader)
#     train_acc = train_acc / len(dataloader)
#     return train_loss, train_acc
# 
# def test_step(model: torch.nn.Module,
#               dataloader: torch.utils.data.DataLoader,
#               loss_fn: torch.nn.Module,
#               device: torch.device) -> Tuple[float, float]:
#     """Tests a PyTorch model for a single epoch.
#     Turns a target PyTorch model to "eval" mode and then performs
#     a forward pass on a testing dataset.
#     Args:
#     model: A PyTorch model to be tested.
#     dataloader: A DataLoader instance for the model to be tested on.
#     loss_fn: A PyTorch loss function to calculate loss on the test data.
#     device: A target device to compute on (e.g. "cuda" or "cpu").
#     Returns:
#     A tuple of testing loss and testing accuracy metrics.
#     In the form (test_loss, test_accuracy). For example:
#     (0.0223, 0.8985)
#     """
#     # Put model in eval mode
#     model.eval()
# 
#     # Setup test loss and test accuracy values
#     test_loss, test_acc = 0, 0
# 
#     # Turn on inference context manager
#     with torch.inference_mode():
#         # Loop through DataLoader batches
#         for batch, (X, y) in enumerate(dataloader):
#             # Send data to target device
#             X, y = X.to(device), y.to(device)
# 
#             # 1. Forward pass
#             test_pred_logits = model(X)
# 
#             # 2. Calculate and accumulate loss
#             loss = loss_fn(test_pred_logits, y)
#             test_loss += loss.item()
# 
#             # Calculate and accumulate accuracy
#             test_pred_labels = test_pred_logits.argmax(dim=1)
#             test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))
# 
#     # Adjust metrics to get average loss and accuracy per batch
#     test_loss = test_loss / len(dataloader)
#     test_acc = test_acc / len(dataloader)
#     return test_loss, test_acc
# 
# def train(model: torch.nn.Module,
#           train_dataloader: torch.utils.data.DataLoader,
#           test_dataloader: torch.utils.data.DataLoader,
#           optimizer: torch.optim.Optimizer,
#           loss_fn: torch.nn.Module,
#           epochs: int,
#           device: torch.device) -> Dict[str, List]:
# 
#     # Create empty results dictionary
#     results = {"train_loss": [],
#                "train_acc": [],
#                "test_loss": [],
#                "test_acc": []
#     }
# 
#     # Loop through training and testing steps for a number of epochs
#     for epoch in tqdm(range(epochs)):
#         train_loss, train_acc = train_step(model=model,
#                                           dataloader=train_dataloader,
#                                           loss_fn=loss_fn,
#                                           optimizer=optimizer,
#                                           device=device)
#         test_loss, test_acc = test_step(model=model,
#           dataloader=test_dataloader,
#           loss_fn=loss_fn,
#           device=device)
# 
#         # Print out what's happening
#         print(
#           f"Epoch: {epoch+1} | "
#           f"train_loss: {train_loss:.4f} | "
#           f"train_acc: {train_acc:.4f} | "
#           f"test_loss: {test_loss:.4f} | "
#           f"test_acc: {test_acc:.4f}"
#         )
# 
#         # Update results dictionary
#         results["train_loss"].append(train_loss)
#         results["train_acc"].append(train_acc)
#         results["test_loss"].append(test_loss)
#         results["test_acc"].append(test_acc)
# 
#     # Return the filled results at the end of the epochs
#     return results

# Commented out IPython magic to ensure Python compatibility.
# %%writefile model_builder.py
# """
# Contains PyTorch model code to instantiate a TinyVGG model.
# """
# import torch
# from torch import nn
# 
# class TinyVGG(nn.Module):
#     """Creates the TinyVGG architecture.
#     Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.
#     See the original architecture here: https://poloclub.github.io/cnn-explainer/
#     Args:
#     input_shape: An integer indicating number of input channels.
#     hidden_units: An integer indicating number of hidden units between layers.
#     output_shape: An integer indicating number of output units.
#     """
#     def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:
#         super().__init__()
#         self.conv_block_1 = nn.Sequential(
#           nn.Conv2d(in_channels=input_shape,
#                     out_channels=hidden_units,
#                     kernel_size=3,
#                     stride=1,
#                     padding=0),
#           nn.ReLU(),
#           nn.Conv2d(in_channels=hidden_units,
#                     out_channels=hidden_units,
#                     kernel_size=3,
#                     stride=1,
#                     padding=0),
#           nn.ReLU(),
#           nn.MaxPool2d(kernel_size=2,
#                         stride=2)
#         )
#         self.conv_block_2 = nn.Sequential(
#           nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),
#           nn.ReLU(),
#           nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),
#           nn.ReLU(),
#           nn.MaxPool2d(2)
#         )
#         self.classifier = nn.Sequential(
#           nn.Flatten(),
#           # Where did this in_features shape come from?
#           # It's because each layer of our network compresses and changes the shape of our inputs data.
#           nn.Linear(in_features=hidden_units*13*13,
#                     out_features=output_shape)
#         )
# 
#     def forward(self, x: torch.Tensor):
#         x = self.conv_block_1(x)
#         x = self.conv_block_2(x)
#         x = self.classifier(x)
#         return x

# Commented out IPython magic to ensure Python compatibility.
# %%writefile utils.py
# """
# Contains various utility functions for PyTorch model training and saving.
# """
# import torch
# from pathlib import Path
# 
# def save_model(model: torch.nn.Module,
#                target_dir: str,
#                model_name: str):
#     """Saves a PyTorch model to a target directory.
#     Args:
#     model: A target PyTorch model to save.
#     target_dir: A directory for saving the model to.
#     model_name: A filename for the saved model. Should include
#       either ".pth" or ".pt" as the file extension.
#     Example usage:
#     save_model(model=model_0,
#                target_dir="models",
#                model_name="05_going_modular_tingvgg_model.pth")
#     """
#     # Create target directory
#     target_dir_path = Path(target_dir)
#     target_dir_path.mkdir(parents=True,
#                         exist_ok=True)
# 
#     # Create model save path
#     assert model_name.endswith(".pth") or model_name.endswith(".pt"), "model_name should end with '.pt' or '.pth'"
#     model_save_path = target_dir_path / model_name
# 
#     # Save the model state_dict()
#     print(f"[INFO] Saving model to: {model_save_path}")
#     torch.save(obj=model.state_dict(),
#              f=model_save_path)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile train.py
# """
# Trains a PyTorch image classification model using device-agnostic code.
# """
# 
# import os
# import argparse
# 
# import torch
# 
# from torchvision import transforms
# 
# import data_setup, engine, model_builder, utils
# 
# # Create a parser
# parser = argparse.ArgumentParser(description="Get some hyperparameters.")
# 
# # Get an arg for num_epochs
# parser.add_argument("--num_epochs",
#                      default=10,
#                      type=int,
#                      help="the number of epochs to train for")
# 
# # Get an arg for batch_size
# parser.add_argument("--batch_size",
#                     default=32,
#                     type=int,
#                     help="number of samples per batch")
# 
# # Get an arg for hidden_units
# parser.add_argument("--hidden_units",
#                     default=10,
#                     type=int,
#                     help="number of hidden units in hidden layers")
# 
# # Get an arg for learning_rate
# parser.add_argument("--learning_rate",
#                     default=0.001,
#                     type=float,
#                     help="learning rate to use for model")
# 
# # Create an arg for training directory
# parser.add_argument("--train_dir",
#                     default="data/pizza_steak_sushi/train",
#                     type=str,
#                     help="directory file path to training data in standard image classification format")
# 
# # Create an arg for test directory
# parser.add_argument("--test_dir",
#                     default="data/pizza_steak_sushi/test",
#                     type=str,
#                     help="directory file path to testing data in standard image classification format")
# 
# # Get our arguments from the parser
# args = parser.parse_args()
# 
# # Setup hyperparameters
# NUM_EPOCHS = args.num_epochs
# BATCH_SIZE = args.batch_size
# HIDDEN_UNITS = args.hidden_units
# LEARNING_RATE = args.learning_rate
# print(f"[INFO] Training a model for {NUM_EPOCHS} epochs with batch size {BATCH_SIZE} using {HIDDEN_UNITS} hidden units and a learning rate of {LEARNING_RATE}")
# 
# # Setup directories
# train_dir = args.train_dir
# test_dir = args.test_dir
# print(f"[INFO] Training data file: {train_dir}")
# print(f"[INFO] Testing data file: {test_dir}")
# 
# # Setup target device
# device = "cuda" if torch.cuda.is_available() else "cpu"
# 
# # Create transforms
# data_transform = transforms.Compose([
#   transforms.Resize((64, 64)),
#   transforms.ToTensor()
# ])
# 
# # Create DataLoaders with help from data_setup.py
# train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(
#     train_dir=train_dir,
#     test_dir=test_dir,
#     transform=data_transform,
#     batch_size=BATCH_SIZE
# )
# 
# # Create model with help from model_builder.py
# model = model_builder.TinyVGG(
#     input_shape=3,
#     hidden_units=HIDDEN_UNITS,
#     output_shape=len(class_names)
# ).to(device)
# 
# # Set loss and optimizer
# loss_fn = torch.nn.CrossEntropyLoss()
# optimizer = torch.optim.Adam(model.parameters(),
#                              lr=LEARNING_RATE)
# 
# # Start training with help from engine.py
# engine.train(model=model,
#              train_dataloader=train_dataloader,
#              test_dataloader=test_dataloader,
#              loss_fn=loss_fn,
#              optimizer=optimizer,
#              epochs=NUM_EPOCHS,
#              device=device)
# 
# # Save the model with help from utils.py
# utils.save_model(model=model,
#                  target_dir="models",
#                  model_name="05_going_modular_script_mode_tinyvgg_model.pth")



"""# 3. Create a Python script to predict (such as predict.py) on a target image given a file path with a saved model."""

# Commented out IPython magic to ensure Python compatibility.
# 
# %%writefile predict.py
# import torch
# import torchvision
# import argparse
# 
# import model_builder
# 
# # Creating a parser
# parser = argparse.ArgumentParser()
# 
# # Get an image path
# parser.add_argument("--image",
#                     help="target image filepath to predict on")
# 
# # Get a model path
# parser.add_argument("--model_path",
#                     default="models/05_going_modular_script_mode_tinyvgg_model.pth",
#                     type=str,
#                     help="target model to use for prediction filepath")
# 
# args = parser.parse_args()
# 
# # Setup class names
# class_names = ["pizza", "steak", "sushi"]
# 
# # Setup device
# device = "cuda" if torch.cuda.is_available() else "cpu"
# 
# # Get the image path
# IMG_PATH = args.image
# print(f"[INFO] Predicting on {IMG_PATH}")
# 
# # Function to load in the model
# def load_model(filepath=args.model_path):
#   # Need to use same hyperparameters as saved model
#   model = model_builder.TinyVGG(input_shape=3,
#                                 hidden_units=128,
#                                 output_shape=3).to(device)
# 
#   print(f"[INFO] Loading in model from: {filepath}")
#   # Load in the saved model state dictionary from file
#   model.load_state_dict(torch.load(filepath))
# 
#   return model
# 
# # Function to load in model + predict on select image
# def predict_on_image(image_path=IMG_PATH, filepath=args.model_path):
#   # Load the model
#   model = load_model(filepath)
# 
#   # Load in the image and turn it into torch.float32 (same type as model)
#   image = torchvision.io.read_image(str(IMG_PATH)).type(torch.float32)
# 
#   # Preprocess the image to get it between 0 and 1
#   image = image / 255.
# 
#   # Resize the image to be the same size as the model
#   transform = torchvision.transforms.Resize(size=(64, 64))
#   image = transform(image)
# 
#   # Predict on image
#   model.eval()
#   with torch.inference_mode():
#     # Put image to target device
#     image = image.to(device)
# 
#     # Get pred logits
#     pred_logits = model(image.unsqueeze(dim=0)) # make sure image has batch dimension (shape: [batch_size, height, width, color_channels])
# 
#     # Get pred probs
#     pred_prob = torch.softmax(pred_logits, dim=1)
# 
#     # Get pred labels
#     pred_label = torch.argmax(pred_prob, dim=1)
#     pred_label_class = class_names[pred_label]
# 
#   print(f"[INFO] Pred class: {pred_label_class}, Pred prob: {pred_prob.max():.3f}")
# 
# if __name__ == "__main__":
#   predict_on_image()

